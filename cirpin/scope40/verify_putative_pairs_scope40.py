print('Loading libraries...')

import sys
import foldcomp
#import torch
import os
import time
import glob
import argparse
import pandas as pd
import pickle
print('Loaded all libraries')

# Use putative pairs generated by the notebook: scope40_all_v_all_10_comparison.ipynb

##### Arg Parser
main_path = '/home/ubuntu/CIRPIN/'

parser = argparse.ArgumentParser(description='Get verified pairs SCOPe40 Progres/CIRPIN score differences.')
parser.add_argument('--scope', default=os.path.join(main_path, 'scope40/pdbstyle-2.08'), help='path to SCOPe pdb files')
parser.add_argument('--pairs', default=os.path.join(main_path,'scope40/putative_pairs_list_score_diff_0.3_progres_cutoff_0.6_cirpin_cutoff_0.9_.pkl'), help='putative cp pair file')
parser.add_argument('--output_dir', default=os.path.join(main_path,'scope40/scope40_cp_pairs'), help='Output directory for logs')
parser.add_argument('--output_cp_pairs', default=os.path.join(main_path,'scope40/scope40_cp_pairs/cp_pairs_scope40.tsv'), help='Verified pairs')
parser.add_argument('--output_other_homologous_pairs', default=os.path.join(main_path,'scope40/scope40_cp_pairs/other_homologous_pairs_scope40.tsv'), help='Verified pairs')
parser.add_argument('--output_false_pairs', default=os.path.join(main_path,'scope40/scope40_cp_pairs/false_pos_pairs_scope40.tsv'), help='Verified pairs')
parser.add_argument('--output_pairs_unique', default=os.path.join(main_path,'scope40/scope40_cp_pairs/unique_CPs_scope40.txt'), help='Verified pairs')

args = parser.parse_args()

scope_dir = args.scope
putative_pairs_fp = args.pairs
out_dir = args.output_dir
output_cp_pairs = args.output_cp_pairs
output_other_homologous_pairs = args.output_other_homologous_pairs
output_false_pairs = args.output_false_pairs
output_pairs_unique = args.output_pairs_unique

os.makedirs(out_dir, exist_ok=True)

log_file = os.path.join(out_dir, 'verify_putative_pairs.log')

sys.stdout = open(log_file, 'w', buffering=1)
sys.stderr = sys.stdout

def get_pdb_from_scope(scope_id):

    scope_pdb_fp = os.path.join(scope_dir,f'{scope_id}.pdb')
    return scope_pdb_fp

def tmscore(q,t, cp=False):
    ''' Run TM-align and get back TM-align score '''
    if cp:
        output = os.popen(f'/home/ubuntu/TM_tools/TMalign {q} {t} -cp')
    else:
        output = os.popen(f'/home/ubuntu/TM_tools/TMalign {q} {t}')
    tms = {"tms":[]}
    parse_float = lambda x: float(x.split("=")[1].split()[0])

    for line in output:
        line = line.rstrip()
        if line.startswith("TM-score"): 
            tms["tms"].append(parse_float(line))
    min_tms = min(tms['tms'])
    return min_tms


def verify_pairs(pairs_list):
    ''' pairs_list: list of lists of putative pairs'''
    
    # Now process each putative pair
    cp_pairs = []
    # other homolog pairs
    other_homolog_pairs = []
    # false pos pairs
    false_pos_pairs = []
    # list of unique, non duplicated structures
    unique_cp_structures = []
    # Get number of putative pairs
    num_pairs = len(pairs_list)
    num_pairs_processed = 0
    
    for pair in pairs_list:
        q = pair[0]  # query TED ID
        t = pair[1]  # target TED ID
        # Progres and cirpin scores saved to the list of putative cps too. 
        prog_score = pair[2]
        cirpin_score = pair[3]

        q_pdb = get_pdb_from_scope(q)

        t_pdb = get_pdb_from_scope(t)


        tm_score_cp = tmscore(q_pdb,t_pdb, cp=True)

        if tm_score_cp >= 0.5:
            tm_score = tmscore(q_pdb,t_pdb, cp=False)
            tm_diff = tm_score_cp - tm_score
            if tm_diff > 0:
                cp_pairs.append([q, t, prog_score, cirpin_score, tm_score, tm_score_cp, tm_diff])
                print(
                    f'Domains {q}, {t} have a tm_score -cp of {tm_score_cp:.2f},' 
                      f'tm score: {tm_score:.2f}, tm_diff: {tm_diff:.2f}, progres: {prog_score:.2f},'
                      f'cirpin: {cirpin_score:.2f}!', 
                      flush=True
                )
                if q not in unique_cp_structures:
                    unique_cp_structures.append(q)
                if t not in unique_cp_structures:
                    unique_cp_structures.append(t)
            else:
                other_homolog_pairs.append([q, t, prog_score, cirpin_score, tm_score, tm_score_cp, tm_diff])
            
        else:
            false_pos_pairs.append([q, t, prog_score, cirpin_score, tm_score_cp])
            #print(f'Low TM-score: {tm_score}!', flush=True)

        num_pairs_processed += 1
        print(f'Processed {num_pairs_processed} out of {num_pairs}')

    with open(output_cp_pairs, 'w', encoding='utf-8') as f:
        # Write header once
        f.write("query\ttarget\tprog_score\tcirpin_score\ttm_score\ttm_score_cp\ttm_diff\n")
    
        # Write each cp pair
        for pair in cp_pairs:
            query, target, prog, cirpin, tm_score, tm_score_cp, tm_diff = pair
            f.write(f"{query}\t{target}\t{prog:.2f}\t{cirpin:.2f}\t{tm_score:.2f}\t{tm_score_cp:.2f}\t{tm_diff:.2f}\n")
    
        # Add a blank line before summary section
        f.write("\n")
        num_cp_pairs = len(cp_pairs)
        hits_percentage_cps = (num_cp_pairs / num_pairs) * 100
    
        # Write summary stats, each on its own line
        f.write(f"Number of putative pairs: {num_pairs}\n")
        f.write(f"Number of CP pairs (TM-score difference > 0): {num_cp_pairs}\n")
        f.write(f"Percent of putative CPs that are verified CPs: {hits_percentage_cps:.2f}%\n")
        
    with open(output_other_homologous_pairs, 'w', encoding='utf-8') as f:
        # Write header once
        f.write("query\ttarget\tprog_score\tcirpin_score\ttm_score\ttm_score_cp\ttm_diff\n")
    
        # Write each verified pair
        for pair in other_homolog_pairs:
            query, target, prog, cirpin, tm_score, tm_score_cp, tm_diff = pair
            f.write(f"{query}\t{target}\t{prog:.2f}\t{cirpin:.2f}\t{tm_score:.2f}\t{tm_score_cp:.2f}\t{tm_diff:.2f}\n")
    
        # Add a blank line before summary section
        f.write("\n")
        num_homologous_pairs = len(other_homolog_pairs)
        hits_percentage_homologs = (num_homologous_pairs / num_pairs) * 100
    
        # Write summary stats, each on its own line
        f.write(f"Number of putative pairs: {num_pairs}\n")
        f.write(f"Number of non-CP homologous pairs (TM-score difference == 0): {num_homologous_pairs}\n")
        f.write(f"Percent of putative CPs that are non-CP homologous pairs: {hits_percentage_homologs:.2f}%\n")

    with open(output_false_pairs, 'w', encoding='utf-8') as f:
        # Write header once
        f.write("query\ttarget\tprog_score\tcirpin_score\ttm_score_cp\n")
    
        # Write each verified pair
        for pair in false_pos_pairs:
            query, target, prog, cirpin, tm_score_cp = pair
            f.write(f"{query}\t{target}\t{prog:.2f}\t{cirpin:.2f}\t{tm_score_cp:.2f}\n")
    
        # Add a blank line before summary section
        f.write("\n")
        num_false_pairs = len(false_pos_pairs)
        false_pairs_percentage = (num_false_pairs / num_pairs) * 100
    
        # Write summary stats, each on its own line
        f.write(f"Number of putative pairs: {num_pairs}\n")
        f.write(f"Number of pairs below TM-align -cp score of 0.5: {num_false_pairs}\n")
        f.write(f"Percent of putative CPs that are false positives: {false_pairs_percentage:.2f}%\n")

    with open(output_pairs_unique, 'w', encoding='utf-8') as f:
        for i in unique_cp_structures:
            #f.write(pair + '\n')
            f.write(f"{i}\n")

    print(f'Saved verified pairs of CPS: {output_cp_pairs}, {output_other_homologous_pairs} {output_false_pairs}, {output_pairs_unique}!', flush = True)
    
def main():
    # Load putative pairs
    with open(putative_pairs_fp, 'rb') as f:
        putative_pairs = pickle.load(f)

    # verify pairs
    verify_pairs(putative_pairs)

if __name__ == "__main__":
    main()